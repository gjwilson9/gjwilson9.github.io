---
layout: post
title:      "Takeaways From My First Data Science Project"
date:       2020-09-20 19:29:00 +0000
permalink:  takeaways_from_my_first_data_science_project
---

<br>
-Originally written on 2/20/2020-
<br>
My first data science project was overwhelming to say the least. I was tasked with exploring various data sets that contained historical movie data.   The goal was to  unveil pertinent insights into past trends that could be used in the future as film investment guidelines for risk mitigation and maximum profitability. 
<br>
Having zero coding background one month ago, I've come a long way. The Flatiron School kick-started the arduous, yet exciting, task of learning an entirely new language from scratch - Python - but this project set the learning process into overdrive. There were countless struggles, and some minor victories along the way. Here, I will recount what I've learned during my very first data science project,  and what I need to work on. Sorry, no code in my very first blog post.
<br>
My previous profession as an exploration geologist for an oil company in southern California had me constantly dealing with enormous data sets. The data were filled with all the information one would want to know - and more- about the subsurface. Anything ranging from fluid properties in porous rock, to chemical composition of mineral assemblages, to radioactivity of certain rock layers, all the way up to variability of acoustic wave velocities through thousands of feet of vertical stratigraphy. The scales in which I worked were wide ranging, the data to interpret were endless, but i knew what I was doing. So, I could decipher, interpret, and model with ease.
<br>
Coding is different. When initially exploring the data about movies, I came up with a plethora of questions I would like to answer.
<br>
The first step was to adequately clean the data, so subsequent steps and interpretations aren't negatively affected. After cleaning the data, I went about trying to answer the list of questions I came up with. I very quickly realized how little I knew when I'd come to a line of code I couldn't complete, or figure out. Initially, I considered it best practice to move onto another question to see if I could answer that question with what limited python skills I have. Then the next road block would hit, and I'd press on to the next. Bad idea. 
<br>
After jumping around trying to solve various questions without success, I turned to more simple questions. The questions I settled on were manageable, but the damage had already been done to my data without my knowledge. I went about nearly completing the assignment before I'd realized somewhere along the way, after many merged dataframes, that my data was bad. My jupyter notebook was so poorly organized by all my previous jumping around I ended up having to start over. This ended up being a curse and a blessing.
<br>
A curse because I was further behind than before, and a blessing because I learned a lot from going through the project a second time - the right way.
<br>
The second time around, I was much more organized in my notebook, which helped me understand the code and the overall process more clearly. I also focused on finishing the issue at hand before moving on. This helped mitigate the dumpster fire that was blazing in my mind the first go around, which immensely cleared my thought process. I was able to ingrain the processes more soundly, while adding some code I had previously overlooked the first time through.
<br>
The questions I answered ended up being more elementary than I would've liked just due to inexperience. However, I know this will come in time. I learned a lot during my very first data science project, but there's a lot more to learn.
<br>
Two main takeaways: stay organized, solve one problem before moving onto the next.
